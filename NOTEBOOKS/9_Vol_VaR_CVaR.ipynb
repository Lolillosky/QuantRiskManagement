{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantitative Risk Management\n",
    "\n",
    "Click <a href=\"https://colab.research.google.com/github/Lolillosky/QuantRiskManagement/blob/main/NOTEBOOKS/9_Vol_VaR_CVaR.ipynb\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/d/d0/Google_Colaboratory_SVG_Logo.svg\" width=\"30\" alt=\"Google Colab\">\n",
    "</a> to open this notebook in Google Colab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you will calculate sensitivities, VaR and CVaR of a portfolio under different assumptions.\n",
    "\n",
    "The portfolio will be comprised of the following:\n",
    "\n",
    "* +1 share and a long put option with strike $125$ on A.\n",
    "* +1 share and a short call option with strike $150$ on B.\n",
    "* A short call option with strike $135$ on C.\n",
    " \n",
    "Every option has a maturity equal to 6 months. Value date is 07-12-2022 (last date in the data frame). Assume risk free rate is $1\\%$ and dividend yields $0\\%$. Give an estimate of the sensitivities, volatility, value at risk and conditional value at risk of your portfolio for a ten day horizon. VaR and CVaR should have a $97.5\\%$ confidence level. \n",
    "\n",
    "Volatilities are in percentage (should be divided by $100$). Use the Black Scholes implementation provided in the repository.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Main Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries from Github Repository "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../CODE')  # Adjust the path as necessary\n",
    "\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "!rm -r {'QuantRiskManagement'}\n",
    "\n",
    "!git clone https://github.com/Lolillosky/QuantRiskManagement.git\n",
    "\n",
    "import sys\n",
    "sys.modules.pop\n",
    "sys.path.insert(0,'QuantRiskManagement/CODE')\n",
    "\n",
    "clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Option_formulas\n",
    "import pytorch_option_formulas\n",
    "import portfolio_npv_calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Historica Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#risk_factors = pd.read_csv('../DATA/Histdata_equity.csv',index_col=0,parse_dates=True)\n",
    "risk_factors = pd.read_csv('/content/QuantRiskManagement/DATA/Histdata_equity.csv',index_col=0,parse_dates=True)\n",
    "\n",
    "risk_factors['Vol A'] /= 100\n",
    "risk_factors['Vol B'] /= 100\n",
    "risk_factors['Vol C'] /= 100\n",
    "\n",
    "risk_factors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Scenario Delta Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notionals = np.array([1.0, 1.0, 1.0, -1.0, -1.0])\n",
    "notionals_torch = torch.tensor(notionals, requires_grad=True)\n",
    "\n",
    "base_scenario = risk_factors.values[-1].reshape(1,-1)\n",
    "base_scenario_torch = torch.tensor(base_scenario, requires_grad=True)\n",
    "\n",
    "portfolio_torch = [lambda t, risk_factors: risk_factors[:,0],\n",
    "            lambda t, risk_factors: pytorch_option_formulas.BlackScholes(risk_factors[:,0], torch.tensor(125.0),\n",
    "                torch.tensor(0.5)-t, torch.tensor(0.01), torch.tensor(0.0), risk_factors[:,1], False),\n",
    "            lambda t, risk_factors: risk_factors[:,2],\n",
    "            lambda t, risk_factors: pytorch_option_formulas.BlackScholes(risk_factors[:,2], torch.tensor(150.0),\n",
    "                torch.tensor(0.5)-t, torch.tensor(0.01), torch.tensor(0.0), risk_factors[:,3], True),\n",
    "            lambda t, risk_factors: pytorch_option_formulas.BlackScholes(risk_factors[:,4], torch.tensor(135.0),\n",
    "                torch.tensor(0.5)-t, torch.tensor(0.01), torch.tensor(0.0), risk_factors[:,5], True)]\n",
    "\n",
    "portfolio = [lambda t,risk_factors: risk_factors[:,0],\n",
    "            lambda t,risk_factors: Option_formulas.BlackScholes(risk_factors[:,0], 125,0.5-t,0.01, 0.0, risk_factors[:,1], False),\n",
    "            lambda t,risk_factors: risk_factors[:,2],\n",
    "            lambda t,risk_factors: Option_formulas.BlackScholes(risk_factors[:,2], 150,0.5-t,0.01, 0.0, risk_factors[:,3], True),\n",
    "            lambda t,risk_factors: Option_formulas.BlackScholes(risk_factors[:,4], 135,0.5-t,0.01, 0.0, risk_factors[:,5], True)]\n",
    "\n",
    "\n",
    "\n",
    "calculator_torch = portfolio_npv_calculations.Portfolio_Delta_NPV_Calculator(notionals_torch,portfolio_torch, option = 'torch')\n",
    "calculator = portfolio_npv_calculations.Portfolio_Delta_NPV_Calculator(notionals,portfolio, option = 'numpy')\n",
    "\n",
    "NPV = calculator_torch.value(torch.tensor(0.0),base_scenario_torch)[0]\n",
    "\n",
    "print(NPV)\n",
    "\n",
    "NPV.backward()\n",
    "\n",
    "delta_vega = base_scenario_torch.grad\n",
    "\n",
    "print(delta_vega)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Valuation Scenarios\n",
    "\n",
    "We will use 10-days overlapping historical scenarios so that for risk factor $\\theta_j$ and scenario i:\n",
    "\n",
    "$$\\theta_j^i=\\theta_j^0\\frac{\\theta_j^{t_i}}{\\theta_j^{t_{i-10}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 10\n",
    "\n",
    "\n",
    "risk_factors_shocked = base_scenario* risk_factors.values[horizon:]/risk_factors.values[:-horizon]\n",
    "        \n",
    "\n",
    "portfolio_pl, constituents_pl = calculator.compute_scenarios_pl(base_scenario,0,risk_factors_shocked)\n",
    "\n",
    "\n",
    "plt.hist(portfolio_pl,bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a quick check: for the whole set of scenarios, compute the volatility using numpy np.std function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the calculation with the covariance matrix formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the marginal contribution to volatility with the formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the marginal contribution to volatility with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a rolling window of 250 scenarios over the 10 day historical shocks, compare the volatility obtained with full valuation with that obtained with sensitivities and with that obtained by the delta normal approach.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value at Risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the whole set of scenarios, compute VaR using numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the marginal contribution to VaR with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a rolling window of 250 scenarios over the 10 day historical shocks, compare the VaR obtained with full valuation with that obtained with sensitivities and with that obtained by the delta normal approach.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Value at Risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the whole set of scenarios, compute CVaR using numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the marginal contribution to CVaR with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a rolling window of 250 scenarios over the 10 day historical shocks, compare the CVaR obtained with full valuation with that obtained with sensitivities and with that obtained by the delta normal approach.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "definitive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
