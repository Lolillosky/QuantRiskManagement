{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantitative Risk Management\n",
    "\n",
    "Click <a href=\"https://colab.research.google.com/github/Lolillosky/QuantRiskManagement/blob/main/NOTEBOOKS/3_AD_Pytorch.ipynb\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/d/d0/Google_Colaboratory_SVG_Logo.svg\" width=\"30\" alt=\"Google Colab\">\n",
    "</a> to open this notebook in Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to AD in Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to install Pythorch in your machine follow the instructions from [Pythorch help](https://pytorch.org/). The library is already installed in Google Colab environment.\n",
    "\n",
    "In order to import the library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "\n",
    "In order to be able to compute derivatives, we have to work with Pytorch tensors. These can be initialized from hardcoded values, numpy variables or Pythorch functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(3.0)\n",
    "\n",
    "y_numpy = np.linspace(0,2*np.pi,10)\n",
    "\n",
    "y = torch.tensor(y_numpy)\n",
    "\n",
    "z = torch.linspace(0,2*np.pi,10)\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The floating point precission can be set when a variable is created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(3.0, dtype= torch.float64)\n",
    "\n",
    "y_numpy = np.linspace(0,2*np.pi,10)\n",
    "\n",
    "y = torch.tensor(y_numpy, dtype= torch.float64)\n",
    "\n",
    "z = torch.linspace(0,2*np.pi,10, dtype= torch.float64)\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default floating point precision can alse be set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be able to perform AD, we must specify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "y = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "z = x**2 + x*y\n",
    "\n",
    "z.backward()\n",
    "\n",
    "print(x.grad)\n",
    "print(y.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the exception of basic operations (+,-*,/), we must use pytorch functions. Pytorch functions and usage resemble numpy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(0, 2*np.pi, 100, requires_grad=True)\n",
    "y = torch.sin(x)\n",
    "z = torch.sum(y)\n",
    "\n",
    "z.backward()\n",
    "\n",
    "grad = x.grad\n",
    "\n",
    "plt.plot(x.detach().numpy(), y.detach().numpy(), label = 'sin(x)')\n",
    "plt.plot(x.detach().numpy(), grad, label = r'$\\frac{d\\sin(x)}{dx}$')\n",
    "\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the numerical content of every tensor, but in AD has been enabled on the particular tensor, we must first detach it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever we compute gradients, the tape is deleted unless we tell Pytorch not to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0,2.0,3.0], requires_grad=True)\n",
    "\n",
    "y = torch.tensor([1.5,3.25,3.47], requires_grad=True)\n",
    "\n",
    "z1 = torch.sum(x**2 - y**2)\n",
    "z2 = z1**2\n",
    "\n",
    "\n",
    "z1.backward()\n",
    "z2.backward()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0,2.0,3.0], requires_grad=True)\n",
    "\n",
    "y = torch.tensor([1.5,3.25,3.47], requires_grad=True)\n",
    "\n",
    "z1 = torch.sum(x**2 - y**2)\n",
    "z2 = z1**2\n",
    "\n",
    "\n",
    "z1.backward(retain_graph=True)\n",
    "z2.backward()\n",
    "\n",
    "print(x.grad)\n",
    "print(y.grad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can disable tape recording without setting requires_grad to false:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(0, 2*np.pi, 100, requires_grad=True)\n",
    "\n",
    "y1 = torch.sin(x)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y2 = torch.sin(x)\n",
    "\n",
    "print(y1)\n",
    "print(y2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Jacobian Matrix\n",
    "\n",
    "Let us first define a function that takes several inputs and outputs. For example, a formula that computes the Montecarlo price of both a call and a put option given a set of parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MC_payoffs(spot, strike, vol, r, div, ttm, num_sims):\n",
    "\n",
    "    brow = torch.tensor(np.random.normal(0,1,num_sims))*torch.sqrt(ttm)\n",
    "    \n",
    "    spot_mat = spot*torch.exp((r-div-0.5*vol*vol)*ttm + vol*brow)\n",
    "\n",
    "    call = torch.mean(torch.maximum(spot_mat - strike, torch.tensor(0.0)))*torch.exp(-r*ttm)\n",
    "    put = torch.mean(torch.maximum(-spot_mat + strike, torch.tensor(0.0)))*torch.exp(-r*ttm)\n",
    "\n",
    "    return (call, put)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make a wrapper to this function, so that the wrapper only takes as inputs the parameters with respect to which we want to compute the Jacobian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spot = torch.tensor(1.0, requires_grad=True)\n",
    "strike = torch.tensor(1.0, requires_grad=True)\n",
    "vol = torch.tensor(0.2, requires_grad=True)\n",
    "r = torch.tensor(0.01, requires_grad=True)\n",
    "div = torch.tensor(0.005, requires_grad=True)\n",
    "ttm = torch.tensor(1.0, requires_grad=True)\n",
    "num_sims = 50000\n",
    "\n",
    "MC_100000 = lambda spot, strike, vol, r, div, ttm: MC_payoffs(spot, strike, vol, r, div, ttm, 100000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the Jacobian, do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd.functional import jacobian\n",
    "jacobian(MC_100000, (spot, strike, vol, r, div, ttm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High order differentials\n",
    "\n",
    "To compute high order differential, we must use torch.autograd.grad function iteratively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "y = 3*x**3-2.5*x**2+x+1\n",
    "\n",
    "first_der = torch.autograd.grad(y,x,retain_graph= True, create_graph= True)\n",
    "\n",
    "print(first_der)\n",
    "\n",
    "second_der = torch.autograd.grad(first_der,x,retain_graph= True, create_graph= True)\n",
    "\n",
    "print(second_der)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpointing\n",
    "\n",
    "To illustrate how to perform checkpointing, let's assume that we have to price a basket option with payoff function:\n",
    "\n",
    "$$V_{T}=\\left(\\frac{1}{m} \\sum_{j=1}^{m} \\frac{S_{T}^j}{S_{0}^j}-1\\right)^+$$\n",
    "\n",
    "Let's assume the following:\n",
    "$\\rho_{ij}=0.6\\ \\forall i,j$; $S_0^j=0.8+0.4j/m$; $\\sigma^j=0.25-0.1j/m$; maturity=1yr; initial spot value = $1.0 \\forall j$ . \n",
    "Assume no dividends and $r = 0.01$.\n",
    "\n",
    "We have implemented two different functions:\n",
    "\n",
    "* simulate_spots: simulates the spot to the product's maturity date.\n",
    "* compute_mc_price: computes the payoff and averages it.\n",
    "\n",
    "Let's apply checkpointing after each one of the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.checkpoint import checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def simulate_spots(num_assets, num_sims, spot, vols, r, d, rho, ttm):\n",
    "\n",
    "    norm_ind = torch.tensor(np.random.normal(0,1,(num_assets, num_sims)))\n",
    "    norm_common = torch.tensor(np.random.normal(0,1,(1, num_sims)))\n",
    "\n",
    "    brow_correl = (torch.sqrt(rho)*norm_common + torch.sqrt(1-rho)*norm_ind)*torch.sqrt(ttm)\n",
    "\n",
    "\n",
    "    return spot*torch.exp((r-d-0.5*vols*vols)*1 + vols*brow_correl)\n",
    "\n",
    "def compute_mc_price(spots_t, indiv_strikes, strike, r, ttm):\n",
    "\n",
    "    gross_return = spots_t/indiv_strikes\n",
    "\n",
    "    mean_gross_return = torch.mean(gross_return, axis = 0)\n",
    "\n",
    "    return torch.mean(torch.maximum(mean_gross_return - strike, torch.tensor(0.0)))*torch.exp(-r*ttm)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_assets = 300\n",
    "num_sims = 100000\n",
    "rho = torch.tensor(0.6, requires_grad=True)\n",
    "ttm = torch.tensor(1.0, requires_grad=True)\n",
    "r = torch.tensor(0.01, requires_grad=True)\n",
    "d = torch.tensor(0.05, requires_grad=True)\n",
    "\n",
    "spot = torch.tensor(np.ones((num_assets,1)), requires_grad=True)\n",
    "\n",
    "indiv_strikes = torch.tensor(np.array([0.8 + 0.4*j/num_assets for j in range(num_assets)]).reshape(num_assets,1), requires_grad=True)\n",
    "vols = torch.tensor(np.array([0.25 - 0.1*j/num_assets for j in range(num_assets)]).reshape(num_assets,1), requires_grad=True)\n",
    "\n",
    "spots_t = checkpoint(simulate_spots,num_assets, num_sims, spot, vols, r, d, rho, ttm, use_reentrant=True)\n",
    "\n",
    "price = checkpoint(compute_mc_price, spots_t, indiv_strikes, 1.0, r, ttm, use_reentrant=True)\n",
    "\n",
    "price.backward()\n",
    "\n",
    "print(price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(spot.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "definitive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
