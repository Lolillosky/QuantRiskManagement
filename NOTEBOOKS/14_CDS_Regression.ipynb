{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantitative Risk Management\n",
    "\n",
    "Click <a href=\"https://colab.research.google.com/github/Lolillosky/QuantRiskManagement/blob/main/NOTEBOOKS/14_CDS_Regression.ipynb\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/d/d0/Google_Colaboratory_SVG_Logo.svg\" width=\"30\" alt=\"Google Colab\">\n",
    "</a> to open this notebook in Google Colab.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you are going to bootstrap a zero coupon curve from par swap rates. After that, you will bootstrap a survival probability curve from CDS quotes.\n",
    "\n",
    "## Import main libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the following libraries from the repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../CODE')  # Adjust the path as necessary\n",
    "\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "'''\n",
    "!rm -r {'QuantRiskManagement'}\n",
    "\n",
    "!git clone https://github.com/Lolillosky/QuantRiskManagement.git\n",
    "\n",
    "import sys\n",
    "sys.modules.pop\n",
    "sys.path.insert(0,'QuantRiskManagement/CODE')\n",
    "'''\n",
    "clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CDS_Data = pd.read_csv('../DATA/CDS_Data.csv', sep=';')\n",
    "#CDS_Data = pd.read_csv('/content/QuantRiskManagement/DATA/CDS_Data.csv', sep=';')\n",
    "\n",
    "# We print the data columns\n",
    "print(CDS_Data.columns)\n",
    "CDS_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are just interested in the columns that we are using as features \n",
    "# and the one we want to predict\n",
    "CDS_Data = CDS_Data[['Tier', 'Sector', 'Region','AvRating', 'Spread5Y', 'Recovery']] \n",
    "\n",
    "# We print the original length of the dataframe\n",
    "print('Original dataframe length:', len(CDS_Data))\n",
    "\n",
    "# We get rid of rows with no rating or no 5yr spread. \n",
    "CDS_Data.dropna(subset = ['Spread5Y', 'AvRating'], inplace = True)\n",
    "\n",
    "# For the remaining columns, we fill NAs with 'Unkown' keyword\n",
    "CDS_Data.fillna('Unknown', inplace=True)\n",
    "\n",
    "# In the Sector column, there are some examples marked as 'Unclassified'.\n",
    "# We change it to 'Unkown'\n",
    "CDS_Data.loc[CDS_Data['Sector'] == 'Unclassified','Sector'] = 'Unknown'\n",
    "\n",
    "# We convert both the CDS spread and the implied recovery rate to float\n",
    "CDS_Data['Spread5Y'] = CDS_Data['Spread5Y'].str.rstrip('%').astype('float') / 100.0\n",
    "CDS_Data['Recovery'] = CDS_Data['Recovery'].str.rstrip('%').astype('float') / 100.0\n",
    "\n",
    "# We get rid of defaulted names\n",
    "CDS_Data = CDS_Data[CDS_Data['AvRating']!='D']\n",
    "\n",
    "# We add the clean spread column\n",
    "CDS_Data['Clean Spd'] = CDS_Data['Spread5Y'] / (1-CDS_Data['Recovery'])\n",
    "\n",
    "# We print the length of the dataframe we are working with\n",
    "print('NA filtered dataframe length:', len(CDS_Data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that the features that we are using are all categorical.\n",
    "# Let's print their unique values and their ocurrence\n",
    "\n",
    "print('----------Tier------------------------------------')\n",
    "print(CDS_Data['Tier'].value_counts())\n",
    "print('----------Sector----------------------------------')\n",
    "print(CDS_Data['Sector'].value_counts())\n",
    "print('----------Region----------------------------------')\n",
    "print(CDS_Data['Region'].value_counts())\n",
    "print('----------AvRating--------------------------------')\n",
    "print(CDS_Data['AvRating'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1)\n",
    "\n",
    "CDS_Data[CDS_Data.AvRating=='AA']['Clean Spd'].hist(bins = 20, ax = ax, alpha = 0.5, label = 'AAA')\n",
    "CDS_Data[CDS_Data.AvRating=='A']['Clean Spd'].hist(bins = 20, ax = ax, alpha = 0.5,label = 'A')\n",
    "CDS_Data[CDS_Data.AvRating=='BBB']['Clean Spd'].hist(bins = 20, ax = ax, alpha = 0.5,label = 'BBB')\n",
    "# CDS_data[CDS_data.AvRating=='BB']['Clean Spd'].hist(bins = 20, ax = ax, alpha = 0.5, label = 'BB')\n",
    "\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "# We define the pipeline steps\n",
    "steps = [('OneHot', OneHotEncoder(sparse_output=False, handle_unknown  = 'error')),\n",
    "         ('Ridge', Ridge(fit_intercept=True, alpha = 10))]\n",
    "\n",
    "# Pipeline is defined\n",
    "pipeline = Pipeline(steps)\n",
    "          \n",
    "# Grid of hyperparams\n",
    "parameters = {'Ridge__alpha': np.logspace(-4,0,100)}\n",
    "\n",
    "# Grid search is defined. Here we do 5-fold cv\n",
    "grid = GridSearchCV(pipeline, param_grid=parameters, cv=5, verbose = 0, refit=True, \n",
    "                    scoring= 'r2', return_train_score = True)\n",
    "\n",
    "# We fill X & Y\n",
    "X = CDS_Data[['Tier', 'Sector','Region','AvRating']]\n",
    "Y = np.log(CDS_Data['Clean Spd'])  \n",
    "\n",
    "# We shuffle the data\n",
    "X, Y = shuffle(X,Y)\n",
    "          \n",
    "# We use the grid as if it was a model\n",
    "grid.fit(X,Y);\n",
    "\n",
    "# We plot the score for both train and test\n",
    "plt.plot(np.logspace(-4,0,100), grid.cv_results_['mean_test_score'], label = 'test ' + r'$r^2$')\n",
    "plt.plot(np.logspace(-4,0,100), grid.cv_results_['mean_train_score'], label = 'train ' r'$r^2$')\n",
    "\n",
    "# We plot the best model\n",
    "plt.plot(grid.best_params_['Ridge__alpha'], grid.best_score_,'o')\n",
    "\n",
    "plt.xlabel(r'$\\lambda$')\n",
    "plt.ylabel(r'$r^2$')\n",
    "\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.legend();\n",
    "\n",
    "print('Best param found: ', grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#@title CDS Spread Prediction { run: \"auto\" }\n",
    "Type1 = \"SNRFOR\" #@param [\"SNRFOR\", \"SUBLT2\", \"SECDOM\", \"SNRLAC\"]\n",
    "Sector1 = \"Financial\" #@param [\"Unknown\", \"Financial\", \"Industrial\", \"Consumer Cyclical\", \"Communications and Technology\", \"Consumer Stable\", \"Utilities\", \"Government\", \"Energy\", \"Materials\"] \n",
    "Region1 = \"Europe\" #@param [\"N.Amer\",\"Europe\",\"Asia\",\"Lat.Amer\",\"MiddleEast\",\"Oceania\",\"E.Eur\",\"India\",\"OffShore\",\"Africa\",\"Supra\",\"Caribbean\"] \n",
    "\n",
    "Type2 = \"SNRFOR\" #@param [\"SNRFOR\", \"SUBLT2\", \"SECDOM\", \"SNRLAC\"]\n",
    "Sector2 = \"Industrial\" #@param [\"Unknown\", \"Financial\", \"Industrial\", \"Consumer Cyclical\", \"Communications and Technology\", \"Consumer Stable\", \"Utilities\", \"Government\", \"Energy\", \"Materials\"] \n",
    "Region2 = \"Europe\" #@param [\"N.Amer\",\"Europe\",\"Asia\",\"Lat.Amer\",\"MiddleEast\",\"Oceania\",\"E.Eur\",\"India\",\"OffShore\",\"Africa\",\"Supra\",\"Caribbean\"] \n",
    "\n",
    "rating = np.array([['AAA', 'AA', 'A', 'BBB', 'BB', 'B', 'CCC']]).T\n",
    "\n",
    "data1 = np.array([[Type1,Sector1,Region1]])\n",
    "data1 = np.repeat(data1,7, axis = 0)\n",
    "data1 = np.concatenate((data1, rating), axis = 1)\n",
    "data1 = pd.DataFrame(data1)\n",
    "\n",
    "data2 = np.array([[Type2,Sector2,Region2]])\n",
    "data2 = np.repeat(data2,7, axis = 0)\n",
    "data2 = np.concatenate((data2, rating), axis = 1)\n",
    "data2 = pd.DataFrame(data2)\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(1)\n",
    "\n",
    "ax.bar(x = np.arange(0,data1.shape[0])-0.2,\n",
    "       height =np.exp(grid.predict(data1)), width = 0.4, \n",
    "       label = 'Data 1')\n",
    "\n",
    "\n",
    "ax.bar(x = np.arange(0,data2.shape[0])+0.2,\n",
    "       height =np.exp(grid.predict(data2)), width = 0.4,\n",
    "      label = 'Data 2')\n",
    "\n",
    "\n",
    "ax.set_xticks(np.arange(0,data1.shape[0]))\n",
    "\n",
    "ax.set_xticklabels(['AAA', 'AA', 'A', 'BBB', 'BB', 'B', 'CCC']);\n",
    "ax.legend();\n",
    "#ax.set_yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "definitive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
